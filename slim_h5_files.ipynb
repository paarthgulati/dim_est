{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479cdaee-7d48-4972-9667-c64ef9062d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "The h5 files had a loooong string for dirty diff, which logged all the code changes since last git commit when run -- led to a 100x bloat in file size.  \n",
    "This includes all the deletions, additions to notebook outside the code as well. \n",
    "This code makes a copy of the h5 file that deletes the dirty diff field and deletes the original.\n",
    "Now that field is omitted in the code logs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1e983f3-bf47-456e-8536-ce95fdd4ef2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary slim file: h5_results/hp_sweep_infinite_joint_gaussian.h5.tmp_slim\n",
      "Total HDF5 nodes to process: 1921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Slimming file: 100%|██████████| 1921/1921 [00:03<00:00, 506.64node/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slim file complete: h5_results/hp_sweep_infinite_joint_gaussian.h5.tmp_slim\n",
      "Backing up original file to: h5_results/hp_sweep_infinite_joint_gaussian.h5.backup_before_slim\n",
      "Replacing original file with slimmed file...\n",
      "Done!\n",
      "Backup saved as: h5_results/hp_sweep_infinite_joint_gaussian.h5.backup_before_slim\n",
      "Slimmed file is now: h5_results/hp_sweep_infinite_joint_gaussian.h5\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "FILE = \"h5_results/hp_sweep_infinite_joint_gaussian.h5\"\n",
    "TMP = FILE + \".tmp_slim\"\n",
    "\n",
    "print(\"Creating temporary slim file:\", TMP)\n",
    "\n",
    "# First, collect all node names for tqdm\n",
    "with h5py.File(FILE, \"r\") as f:\n",
    "    all_items = []\n",
    "    def collect(name, obj):\n",
    "        all_items.append(name)\n",
    "    f.visititems(collect)\n",
    "\n",
    "print(f\"Total HDF5 nodes to process: {len(all_items)}\")\n",
    "\n",
    "with h5py.File(FILE, \"r\") as f_src, h5py.File(TMP, \"w\") as f_dst:\n",
    "\n",
    "    # NEW: copy root-level attributes (schema_version, created_at, tool, etc.)\n",
    "    for k, v in f_src.attrs.items():\n",
    "        f_dst.attrs[k] = v\n",
    "\n",
    "    for name in tqdm(all_items, desc=\"Slimming file\", unit=\"node\"):\n",
    "        obj = f_src.get(name)\n",
    "\n",
    "        # ---------------- GROUPS ----------------\n",
    "        if isinstance(obj, h5py.Group):\n",
    "            g = f_dst.require_group(name)\n",
    "            for k, v in obj.attrs.items():\n",
    "                g.attrs[k] = v\n",
    "            continue\n",
    "\n",
    "        # ---------------- DATASETS ----------------\n",
    "        if isinstance(obj, h5py.Dataset):\n",
    "\n",
    "            # Intercept the giant JSON dataset\n",
    "            if name.endswith(\"/attrs/json\"):\n",
    "                raw = obj[()]\n",
    "                s = raw.decode(\"utf-8\")\n",
    "                cfg = json.loads(s)\n",
    "\n",
    "                code_block = cfg.get(\"params\", {}).get(\"code\", {})\n",
    "                has_diff = \"dirty_diff\" in code_block\n",
    "\n",
    "                if has_diff:\n",
    "                    del code_block[\"dirty_diff\"]\n",
    "                    slim_json = json.dumps(cfg, sort_keys=True)\n",
    "                    #tqdm.write(f\"[CLEANED] Removed dirty_diff in {name}\")\n",
    "                else:\n",
    "                    # keep as-is, but re-store as vlen str\n",
    "                    slim_json = s\n",
    "                    # tqdm.write(f\"[COPIED] No dirty_diff present in {name}\")\n",
    "\n",
    "                # Create a scalar vlen UTF-8 dataset (no compression)\n",
    "                d = f_dst.create_dataset(\n",
    "                    name,\n",
    "                    data=slim_json,\n",
    "                    dtype=h5py.special_dtype(vlen=str),\n",
    "                )\n",
    "\n",
    "                # copy dataset attributes\n",
    "                for k, v in obj.attrs.items():\n",
    "                    d.attrs[k] = v\n",
    "\n",
    "                continue\n",
    "\n",
    "            # Normal dataset: copy with compression (if allowed)\n",
    "            data = obj[()]\n",
    "            d = f_dst.create_dataset(\n",
    "                name,\n",
    "                data=data,\n",
    "                compression=obj.compression or \"gzip\",\n",
    "                chunks=obj.chunks,\n",
    "            )\n",
    "            for k, v in obj.attrs.items():\n",
    "                d.attrs[k] = v\n",
    "\n",
    "            continue\n",
    "\n",
    "print(\"Slim file complete:\", TMP)\n",
    "\n",
    "# ------- SAFE REPLACEMENT -------\n",
    "backup = FILE + \".backup_before_slim\"\n",
    "print(\"Backing up original file to:\", backup)\n",
    "shutil.move(FILE, backup)\n",
    "\n",
    "print(\"Replacing original file with slimmed file...\")\n",
    "shutil.move(TMP, FILE)\n",
    "\n",
    "print(\"Done!\")\n",
    "print(\"Backup saved as:\", backup)\n",
    "print(\"Slimmed file is now:\", FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5f67ea-2211-4d5a-8312-f5e1cc057b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MI_estimation)",
   "language": "python",
   "name": "mi_estimation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
